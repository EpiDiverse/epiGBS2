---
title: "epiGBS report"
params:
  d: !r Sys.Date()
  dir: dir
  bc: bc
  rmd: report.Rmd
  u: !r Sys.info()['user']
output:
  html_document:
    df_print: paged
---

#### author: `r params$u`

#### date: `r params$d`

```{r setup, include=FALSE}
chooseCRANmirror(graphics=FALSE, ind=33)
usePackage <- function(p)
{
  if (!is.element(p, installed.packages()[,1]))
    install.packages(p, dep = TRUE)
  require(p, character.only = TRUE)
}
usePackage("ggplot2")
usePackage("ggpubr")
usePackage("viridis")
usePackage("plyr")
usePackage("gplots")
usePackage("vcfR")
usePackage("reshape2")
usePackage("knitr")
usePackage("reticulate")

options(stringsAsFactors = FALSE)

knitr::opts_chunk$set(echo = FALSE)
knitr::knit_engines$set(python = reticulate::eng_python)
options(tinytex.verbose = TRUE)


Sys.setenv(dir=params$dir)
path <- params$dir

```

This report contains all important information about your epiGBS analysis. The ouput of this analysis is stored in ``r params$dir``. This report will give you a quick overview of the quality of your results. For more details please always refer to the original (log)files:

File | path
-----|-----
bedfile | ``r params$dir`/mapping/methylation.bed`
snpfile | ``r params$dir`/mapping/snp.vcf.gz`
multiQC-report | ``r params$dir`/multiQC_report.html`
demultiplexing-log | ``r params$dir`/output_demultiplex/demultiplex.log`
stacks-log | ``r params$dir`/output_demultiplex/clone-stacks/process_radtags.clone.log`
mapping-log | ``r params$dir`/mapping/mapping_variantcalling.log`
denovo-log | ``r params$dir`/output_denovo/make_reference.log`

# Tabset {.tabset .tabset-fade .tabset-pills}

## Clones Removal

The PCR clones are removed from the raw sequencing reads using a random nucleotide sequence ("wobble") in the adapters.

Before removal, your raw reads contained `r system(paste0("cat ",params$dir,"/output_demultiplex/demultiplex.log | grep -v '^  Processing' | grep '% clone reads' | cut -f 3 -d ','"), intern=TRUE)`.

The histogram shows how many read sequences you find with a specific number of PCR clones. Ideally, most will occure once "1" only.

```{r fig.cap="Fig. 1: Distribution of clone numbers"}
clone.stats <- system(paste0("cat ",params$dir,"/output_demultiplex/demultiplex.log | awk '/Num/,/^$/'"), intern=TRUE)
clone.stats <- strsplit(clone.stats, "\t")
clone.stats.df <- do.call(rbind, clone.stats)
colnames(clone.stats.df) <- c("Clones", "count")
clone.stats.df <- clone.stats.df[-1, ]
class(clone.stats.df) <- "numeric"
clone.stats.df <- as.data.frame(clone.stats.df)
breaks <- clone.stats.df[,1]
p.clone <- ggplot(clone.stats.df, aes(x=Clones, y=count)) +
  geom_bar(stat="identity", colour="black", lwd=0.5) +
  scale_y_continuous(trans='log2', name = "log2(count)") +
  scale_x_continuous(trans='log2', name = "log2(number of clones)", labels=breaks, breaks=breaks) +
  xlab("Clones") +
  scale_color_viridis(discrete=FALSE, option="C") +
  scale_fill_viridis(discrete=FALSE, option="C") +
  theme_pubr()
p.clone
```

## Demultiplexing

You performed demultiplexing with the process_reads program from stacks. The following stats table will give you information about how many reads were retained after barcode- and RAD-tag (RE cut site) check. For both 1 mismatch is allowed. Check your barcode or your enzyme information if the amount of retained reads is suprisingly low.

```{bash capture="demultiplexing stats"}
cat $dir/output_demultiplex/demultiplex.log | awk '/total sequences/,/^$/'
```

In a well designed study, read numbers per sample should be similar. You can check in the following histogram, if this is true for your current analysis:

```{r fig.cap="Fig.2: Histogram of the number of demultiplexed reads per read file"}
demult.table <- system(paste0("cat ",params$dir,"/output_demultiplex/clone-stacks/process_radtags.clone.log | awk '/^Barcode\tFilename\tTotal\tNoRadTag\tLowQuality\tRetained/,/^$/'"), intern = TRUE)
demult.table <- strsplit(demult.table, "\t")
demult.table.df <- do.call(rbind, demult.table)
colnames(demult.table.df) <- demult.table.df[1, ]
demult.table.df <- demult.table.df[-1, ]
class(demult.table.df[,3:6]) <- "numeric"

demult.table.ret.tot <- rbind(data.frame(demult.table.df[, -c(1,2)], label="Retained"), data.frame(demult.table.df[, -c(1,2)], label="Total"))
demult.table.ret.tot$counts <- c(demult.table.df[,6], demult.table.df[,3])
class(demult.table.ret.tot$counts) <- "numeric"
demult.mu.ret.tot <- ddply(demult.table.ret.tot, "label", summarise, grp.mean=mean(counts))

p.demult.ret.tot <- ggplot(demult.table.ret.tot, aes(x=counts, color=label, fill=label)) +
  geom_histogram(aes(y=..density..), position="identity", alpha=0.7, binwidth=10000)+
  geom_density(alpha=0.2)+
  geom_vline(data=demult.mu.ret.tot, aes(xintercept=grp.mean, color=label),
             linetype="dashed")+
  scale_color_viridis(discrete=TRUE, option="C") +
  scale_fill_viridis(discrete=TRUE, option="C") +
  labs(x="Read Counts", y = "Density")+
  theme_pubr()
p.demult.ret.tot 
```

The efficiency of your BS-treatment can be measured in the (non-)conversion rate. Sequences with a control nucleotide "C" in the forward (R1) read and a "T" in the reverse (R2) read are called "Watson", vice versa "Crick". Sequences with a "C" in both R1 and R2 reads are considered as non-converted. 

```{r non-convesion-rate}
barcodes <- system(paste0("cat ",params$bc, " | cut -f3,4 | sed 's/\t/C-/' | sed 's/$/C/'"), intern=TRUE)
write.table(barcodes, paste0(params$dir,'/bc.cc.txt'), row.names = FALSE, col.names = FALSE, quote = FALSE)
watson <- sum(as.integer(system(paste0("cat " ,params$dir, "/output_demultiplex/clone-stacks/process_radtags.clone.log | grep Watson | cut -f 6"), intern=TRUE)))
crick <- sum(as.integer(system(paste0("cat " ,params$dir, "/output_demultiplex/clone-stacks/process_radtags.clone.log | grep Crick | cut -f 6"), intern=TRUE)))
non.conv <- sum(as.integer(system(paste0("cat ",params$dir, "/output_demultiplex/clone-stacks/process_radtags.clone.log | grep -w -f " ,params$dir, "/bc.cc.txt | cut -f 2"), intern=TRUE)))
non.conv.rate <- round((100*non.conv)/(crick + watson + non.conv), 2)
print(paste0("You have got " ,watson, " Watson reads, " ,crick, " Crick reads and ",non.conv, " non-converted reads. Your non-conversion rate is ",non.conv.rate, " %."))
system(paste0('rm ',params$dir,'/bc.cc.txt'))
```

Also check the multiQC stats for a full overview about the read quality. Please remember: Garbage in --> garbage out.

## De novo reference

During demultiplexing all reads were split into samples and annotated as Watson or Crick strands. This information is used during creation of the de novo reference clusters.

During the first step Watson and Crick forward and reverse reads are or assembled (merged), if they overlap, or joined by adding poly-N, respectively. A low assembly % might indicate a low read quality (on the end of the reads) or an insert size longer than twice your read size.

You assembled reads, when they met the following parameters:

```{bash capture="merge reads parameters"}
cat $dir/output_denovo/make_reference.log | grep -E "(p-value|Minimum overlap)" | sort | uniq
```

The percentage of assembled and un-assembled (joined reads) was:

Crick first, followed by Watson.
```{bash}
cat $dir/output_denovo/make_reference.log | awk '/^Assembled reads/,/^$/' | grep -v .*fastq
```

Assembly and joining of forward and reverse reads is followed by three different clustering steps. In the first step the Watson and Crick reads are deduplicated. Afterwards the deduplicated reads are binarized. Now clustering is performed to cluster binary Watson and Crick reads with each other. The original sequence is restored, followed by clustering the reads based on identity. The identity % can be set in the snakemake config file.

It follows the stats for the first clustering step (deduplication).

Watson-joined:
```{bash capture="Watson-joined"}
cat $dir/output_denovo/make_reference.log | grep -A4 -E 'Reading file .*/join_watson.*.joined.fa.gz' | grep -v -E '(Dereplicating|Sorting|^Reading)'
```

Watson-assembled:
```{bash capture="Watson-assembled"}
cat $dir/output_denovo/make_reference.log | grep -A5 -E 'Reading file .*/join_watson.*.assembled.fastq.gz' | grep -v -E '(Dereplicating|Sorting|^Reading)'
```

Crick-joined:
```{bash capture="Crick-joined"}
cat $dir/output_denovo/make_reference.log | grep -A4 -E 'Reading file .*/join_crick.*.joined.fa.gz' | grep -v -E '(Dereplicating|Sorting|^Reading)'
```

Crick-assembled:
```{bash capture="Crick-assembled"}
cat $dir/output_denovo/make_reference.log | grep -A5 -E 'Reading file .*/join_crick.*.assembled.fastq.gz' | grep -v -E '(Dereplicating|Sorting|^Reading)'
```

It follows the stats of the second clustering step (uc):
```{bash capture="uc stats"}
cat $dir/output_denovo/make_reference.log | grep -A7 -E 'Reading file .*/uc.*.fa' | grep -v -E '(Dereplicating|Sorting|^Writing|^Reading)'
```

It follows the stats of the third clustering step (identity):
```{bash capture="identity clustering stats"}
cat $dir/output_denovo/make_reference.log | grep -A7 -E 'Reading file .*consensus.fa' | grep -v -E '(^Writing|^Reading|^Clustering|^Counting|^Sorting)'
```

## Mapping

To determine variants (SNPs or methylation), sequencing reads are mapped against the reference. Mapping is performed with STAR. A low mapping percentage might indicate low quality of the sequencing reads (e.g. 3' adapter sequences), a non-suitable reference or problems with the de novo sequence creation.

It follows the mapping stats:

Watson-joined:
```{bash capture="mapping stats Watson-joined"}
cat $dir/mapping/mapping_variantcalling.log | awk '/watson_joinedLog.final.out/,/% of reads unmapped: other/' | grep -E "(Uniquely mapped reads %|% of reads)" # gets mappings stats
```

Watson-assembled:
```{bash capture="mapping stats Watson-assembled"}
cat $dir/mapping/mapping_variantcalling.log | awk '/watson_mergedLog.final.out/,/% of reads unmapped: other/' | grep -E "(Uniquely mapped reads %|% of reads)" # gets mappings stats
```

Crick-joined:
```{bash capture="mapping stats Crick-joined"}
cat $dir/mapping/mapping_variantcalling.log | awk '/crick_joinedLog.final.out/,/% of reads unmapped: other/' | grep -E "(Uniquely mapped reads %|% of reads)" # gets mappings stats
```

Crick-assembled:
```{bash capture="mapping stats Crick-assembled"}
cat $dir/mapping/mapping_variantcalling.log | awk '/crick_mergedLog.final.out/,/% of reads unmapped: other/' | grep -E "(Uniquely mapped reads %|% of reads)" # gets mappings stats
```


## SNP calling

The epiGBS pipeline performs SNP calling.
The SNP depth reflects the reliability of a called SNP and depends e.g. from the amount of reads and the mappibility of the reads.

```{r warning=FALSE, fig.cap= "Fig.3: Histogram of average SNP depth over all samples"}
vcf <- read.vcfR(paste0(params$dir,'/mapping/snp.vcf.gz'), verbose = FALSE)
dp <- extract.gt(vcf, element = "DP", as.numeric=TRUE)
```
In total, you have got `r nrow(dp)` SNPs.

The first figure plots the average SNP depth over all sample and shows it as a histogram.
```{r warning=FALSE, fig.cap= "Fig.3: Histogram of average SNP depth over all samples"}
depth.av <- data.frame(rowMeans(dp, na.rm = TRUE, dims = 1))
colnames(depth.av) <- "snp.depth"
depth.av$label <- "snp"
class(depth.av$snp.depth) <- "numeric"
depth.av.mu <- ddply(depth.av, "label", summarise, grp.mean=mean(snp.depth))

p.depth.av <- ggplot(depth.av, aes(x=snp.depth, color=label, fill=label)) +
  geom_histogram(aes(y=..density..), position="identity", alpha=0.7, binwidth=1)+
  geom_density(alpha=0.2)+
  geom_vline(data=depth.av.mu, aes(xintercept=grp.mean, color=label),
             linetype="dashed")+
  scale_color_viridis(discrete=TRUE, option="C") +
  scale_fill_viridis(discrete=TRUE, option="C") +
  labs(x="SNP Depth", y = "Density")+
  xlim(0, 50) +
  theme_pubr()
p.depth.av
```

The second plot(s) shows the SNP depth distribution for each sample.
```{r fig.cap="Fig.4: SNP depth distribution of each sample"}
dpf <- melt(dp, varnames=c('Index', 'Sample'), value.name = 'Depth', na.rm=TRUE)
dpf <- dpf[ dpf$Depth > 0,]

samps_per_row <- 24
myRows <- ceiling(length(levels(dpf$Sample))/samps_per_row) #calculates how many plot rows will be generated for the set row number
myList <- vector(mode = "list", length = myRows)

for(i in 1:myRows){
  myIndex <- c(i*samps_per_row - samps_per_row + 1):c(i*samps_per_row)
  myIndex <- myIndex[myIndex <= length(levels(dpf$Sample))]
  myLevels <- levels(dpf$Sample)[myIndex]
  myRegex <- paste(myLevels, collapse = "$|^")
  myRegex <- paste("^", myRegex, "$", sep = "")
  myList[[i]] <- dpf[grep(myRegex, dpf$Sample),]
  myList[[i]]$Sample <- factor(myList[[i]]$Sample)
}
myPlots <- vector(mode = "list", length = myRows)
for(i in 1:myRows){
  myPlots[[i]] <- ggplot(myList[[i]], aes(x=Sample, y=Depth)) +
    geom_violin(adjust=1.0, scale = "count", trim=TRUE)

  myPlots[[i]] <- myPlots[[i]] + theme_pubr()
  myPlots[[i]] <- myPlots[[i]] + theme(axis.title.x = element_blank(),
                                       axis.text.x = element_text(angle = 60, hjust = 1))
  myPlots[[i]] <- myPlots[[i]] + scale_y_continuous(trans=scales::log2_trans())
  myPlots[[i]] <- myPlots[[i]] + stat_summary(fun.data=mean_sdl, geom="pointrange", color="red", size = 0.25)

  print(myPlots[[i]])

}
```

## Methylation calling

This might be the part, you are interestd in the most. You probably will continue your statistical analysis with the methylation.bed file. Here you will find some simple summarized stats about the methylation calls. Please realize, that all following plots are based on the first 100000 methylation sites because of memory issues.

```{python prep}
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
import numpy
```

```{python read-meth}

df = pd.read_csv(
    f'{r.path}/mapping/methylation.bed',
    nrows=100000,
    sep='\t',
    na_values=['None']
)
```

The following histogram shows the distribution of the number of samples, in which the methylated positions were called.
```{python fig.cap="Fig.5: Distribution of the number of samples, that have a specific methylation site called"}
fig5, ax = plt.subplots(figsize=(7,7))
sns.distplot(pd.DataFrame({" samples": df['samples_called']}).dropna(), kde=False, rug=False)
plt.axvline(numpy.median(pd.DataFrame({" samples": df['samples_called']}).dropna()), color='grey', linestyle='--')
fig5
```

The next bar diagram shows, how many sites you obtained in each context CG, CHG, CHH.
```{python fig.cap="Fig. 6: Number of methylated sites in each context"}
fig6, ax1 = plt.subplots(1, figsize=(10,10))
sns.countplot(x="context", data=df)
fig6
```

```{python transform}
tidy = df.melt(id_vars=['chr', 'pos', 'context', 'samples_called'], var_name='sample', value_name = 'count')
tidy['kind'] = tidy['sample'].str.split('_').str[-1]
tidy['sample'] = tidy['sample'].str.split('_').str[:2].str.join('_')
data = tidy.groupby(['chr', 'pos', 'context', 'samples_called', 'sample', 'kind'])['count'].first().unstack().reset_index()
data['ratio'] = data['methylated'] / data['total']
```

The following diagram shows the distribution of the depth of all methylation sites in all samples.
```{python fig.cap="Fig.7: Distibution of the average depth per methylation site and sample"}
fig7, ax = plt.subplots(figsize=(7,7))
sns.distplot(pd.DataFrame({" total_count": data['total']}).dropna(), kde=False, rug=False)
plt.axvline(numpy.median(pd.DataFrame({" total_count": data['total']}).dropna()), color='grey', linestyle='--')
fig7
```
The following diagram shows the distribution of methylation ratio ("methylated"/"total") in different contexts (CG, CHG, CHH)
```{python fig.cap="Fig.8: Distribution of methylation ratio per context"}
fig8, (ax1, ax2, ax3) = plt.subplots(3, figsize=(10,10))
sns.distplot(pd.DataFrame({" ratio": data[data['context']== 'CG']['ratio']}).dropna(), color = 'brown', hist=True, kde=False, rug=False, ax=ax1).set_title('CG')
sns.distplot(pd.DataFrame({" ratio": data[data['context']== 'CHG']['ratio']}).dropna(), color = 'blue', hist=True, kde=False, rug=False, ax=ax2).set_title('CHG')
sns.distplot(pd.DataFrame({" ratio": data[data['context']== 'CHH']['ratio']}).dropna(), color = 'green', hist=True, kde=False, rug=False, ax=ax3).set_title('CHH')
fig8
```
